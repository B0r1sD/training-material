---
layout: tutorial_hands_on
level: Intermediate
title: Building the LORIS LLR6 Model Using Galaxy ML Tools
zenodo_link: https://zenodo.org/records/13885908
questions:
- How can I build the LORIS LLR6 model published by Chang et al., 2024?
- Which tools can I use in Galaxy to obtain a logistic regression model with my desired hyperparameters?
- How can I evaluate the model to confirm its performance?
objectives:
- Build the LORIS LLR6 model using machine learning tools available in Galaxy for reproducibility.
- Use the PyCaret tool to generate a new model using the LORIS dataset published by Chang et al., 2024.
- Evaluate the created models for reproducibility and robustness by comparing them with the original LORIS LLR6 model.
time_estimation: 2H
key_points:
- Use Galaxy tools to build the identical LORIS LLR6 model published by Chang et al., 2024.
- Use the PyCaret tool to train a new model and confirm the robustness of the study published by Chang et al., 2024.
contributors:
- paulocilasjr 
- qchiujunhao 
- jgoecks
tags:
- LORIS Score Model
- Machine Learning
- PyCaret
- Galaxy-ML tools
---

> <comment-title>PyCaret Model Comparison Tool</comment-title>
>
> The PyCaret Model Comparison tool described in this tutorial is only available at: 
> [Cancer-Galaxy](https://cancer.usegalaxy.org)
>
> Galaxy-ML tools > PyCaret Model Comparison 
>
{:  .comment}

Using a comprehensive dataset of patients treated with immune checkpoint blockade (ICB) and non-ICB-treated patients across 18 solid tumor types, we will develop LORIS (logistic regression-based immunotherapy-response score). The goal is to accurately predict patient responses to the treatment.

To achieve this, we will follow three essential steps: (i) upload patient data training file to Galaxy, (ii) set upt and run the PyCaret Model Comparison Tool to training the best model (iii) evaluate the predictive performance of the model comparing with LORIS model published. Additionally, as a bonus step, we will explore (iv) build the exact model generated by {% cite Chang2024 %}.

![schema of the whole process of training model and test.](../../images/loris_tutorial/explain_model_schema.png "Overview of the process steps to obtain the model from the LORIS dataset.")

> <agenda-title></agenda-title>
>
> In this tutorial, we will cover:
>
> 1. TOC
> {:toc}
>
{: .agenda}

> <comment-title>Background</comment-title>
>
> [LORIS dataset](https://github.com/rootchang/LORIS/blob/main/02.Input/AllData.xlsx) comprises clinical, pathologic, and genomic features
> from a diverse cohort of patients, enabling robust analysis and model development.
> There are 10 different cohort dataset available in the raw data (xlsx): 
> 1)Chowell_train, 2) Chowell_test, 3) MSK1, 4) MSK2, 5) Kato_panCancer, 6) Shim_NSCLC, 7) Vanguri_NSCLC, 8) Ravi_NSCLC, 9) Pradat_panCancer, 10) MSK_nonICB
>
> For the proporse of being conscise in this tutorial, we are going to focus only on 3 cohorts: Chowell_train, Chowell_test and MSK1.
>
{:  .comment}

# Dataset composition to train the model 

Before starting our hands-on, here is a brief explanation of the features we are going to use.

## TMB (Tumor mutation burden)

Tumor mutational burden (TMB) is defined as the total number of somatic mutations within a specified region of the tumor genome. It has been recognized as a biomarker for predicting the efficacy of immune checkpoint blockade (ICB) in solid tumors. The FDA has approved a threshold of 10 mutations per megabase (Mb) as a biomarker for response to ICB treatment.

In this dataset, TMB values range from 0 to over 368 mutations per megabase (mut/Mb), with several extreme values like 368.6 and 93.5. To mitigate the influence of these outliers, TMB values will be truncated at 50 mut/Mb, meaning any value exceeding 50 will be capped at 50. This is crucial because extreme TMB values can disproportionately skew the model's learning process, leading to unreliable predictions.

## Systemic Therapy History

This feature is a binary variable that indicates whether a patient received chemotherapy or targeted therapy prior to immunotherapy. It is coded as 1 if the patient had undergone such treatments before starting immunotherapy and 0 if they had not. The Systemic_therapy_history feature is a binary variable that indicates whether a patient received chemotherapy or targeted therapy prior to immunotherapy. It is coded as 1 if the patient had undergone such treatments before starting immunotherapy and 0 if they had not. 

## Albumin

The albumin feature represents the albumin levels measured in patients, which is an important biomarker often associated with nutritional status and liver function. The values are measured in grams per deciliter (g/dL) and typically range between 2.1 and 4.9 g/dL in the dataset. Higher levels of albumin are generally associated with better overall health and can serve as an indicator of a patient's ability to recover or respond to treatments like immunotherapy.

## Cancer Type

The CancerType feature represents the type of cancer diagnosed in each patient, which can vary significantly across the dataset. Common types include Non-Small Cell Lung Cancer (NSCLC), Small Cell Lung Cancer (SCLC), Melanoma, Endometrial cancer, and other cancer types such as Gastric, Colorectal, Renal, and Breast cancer. This feature is critical for understanding the heterogeneity of the patient cohort and may influence treatment decisions, response rates, and outcomes. 

Incorporating this feature into a machine learning model requires translating the categorical CancerType into one-hot encoded variables. Each cancer type will be represented as a binary feature (0 or 1), with each type becoming a separate column in the dataset. This enables the model to interpret the presence or absence of a specific cancer type for each patient.

## NLR (blood neutrophil–lymphocyte ratio)

The neutrophil–lymphocyte ratio (NLR), a biomarker derived from the ratio of neutrophils to lymphocytes in the blood, is increasingly used in cancer research due to its association with inflammation and immune response. It can serve as a prognostic factor in various cancer types. Higher NLR values often indicate a poorer prognosis, potentially reflecting a more aggressive disease or impaired immune response.

In this dataset, NLR values range, for example from 0.8 to 88, with several extreme outliers. To address this, NLR values will be truncated at 25, meaning any value above 25 will be set to 25. This truncation is important for preventing extreme outliers from disproportionately influencing the machine learning model.

## Age

In predictive models for patient outcomes, age is a crucial feature because it is often correlated with various health factors and disease risks. As people age, their immune systems, metabolism, and ability to recover from illnesses may change, influencing how they respond to treatments, medications, or disease progression. Including age as a feature helps models account for the biological changes that occur over time and can improve the accuracy of predictions across different age groups.

However, there are limits to how predictive age might be, particularly for extreme values. For example, patients over a certain age may share similar health characteristics, and further increases in age may not significantly add predictive value. Truncating age to a maximum value (like 85) helps to avoid overemphasizing small differences between very old patients, where the added predictive power might be negligible.

## Response

The feature Response is a categorical target variable indicating whether patients benefited from immune checkpoint blockade (ICB) therapy, classified as 0 (no benefit) or 1 (benefit). The model is trained using all previous features to predict patient outcomes when ICB is chosen as the treatment.

## Get data

> <hands-on-title> Data Upload </hands-on-title>
>
> 1. Create a new history for this tutorial
> 2. Import the files from [Zenodo]({{ page.zenodo_link }}) or from
>    the shared data library (`GTN - Material` -> `{{ page.topic_name }}`
>     -> `{{ page.title }}`):
>
>    ```
>    https://zenodo.org/api/records/13885908/files/Chowell_test_No_Response.tsv/content
>    https://zenodo.org/api/records/13885908/files/Chowell_train_Response.tsv/content
>    https://zenodo.org/api/records/13885908/files/Chowell_test_Response.tsv/content
>    https://zenodo.org/api/records/13885908/files/MSK1_Response.tsv/content
>    https://zenodo.org/api/records/13885908/files/MSK1_No_Response.tsv/content
>    ```
>    ***TODO***: *Add the files by the ones on Zenodo here (if not added)*
>
>    ***TODO***: *Remove the useless files (if added)*
>
>    {% snippet faqs/galaxy/datasets_import_via_link.md %}
>
>    {% snippet faqs/galaxy/datasets_import_from_data_library.md %}
>
> 3. Rename the datasets
> 4. Check that the datatype
>
>    {% snippet faqs/galaxy/datasets_change_datatype.md datatype="datatypes" %}
>
> 5. Add to each database a tag corresponding to ...
>
>    {% snippet faqs/galaxy/datasets_add_tag.md %}
>
{: .hands_on}

# Title of the section usually corresponding to a big step in the analysis

It comes first a description of the step: some background and some theory.
Some image can be added there to support the theory explanation:

![Alternative text](../../images/image_name "Legend of the image")

The idea is to keep the theory description before quite simple to focus more on the practical part.

***TODO***: *Consider adding a detail box to expand the theory*

> <details-title> More details about the theory </details-title>
>
> But to describe more details, it is possible to use the detail boxes which are expandable
>
{: .details}

A big step can have several subsections or sub steps:


## Sub-step with **Hyperparameter Search**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Hyperparameter Search](toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_searchcv/sklearn_searchcv/1.0.11.0) %} with the following parameters:
>    - *"Select a hyperparameter search algorithm"*: `GridSearchCV - Exhaustive search over specified parameter values for an estimator `
>    - {% icon param-file %} *"Choose the dataset containing pipeline/estimator object"*: `outfile` (output of **Pipeline Builder** {% icon tool %})
>    - In *"Advanced Options for SearchCV"*:
>        - *"Select the primary metric (scoring):"*: `default with estimator`
>        - *"Select the cv splitter:"*: `default splitter`
>    - *"Select input type:"*: `tabular data`
>        - {% icon param-file %} *"Training samples dataset:"*: `output` (Input dataset)
>        - *"Does the dataset contain header:"*: `Yes`
>        - *"Choose how to select data by column:"*: `All columns EXCLUDING some by column index number(s)`
>            - *"Select target column(s):"*: `c['22']`
>        - {% icon param-file %} *"Dataset containing class labels or target values:"*: `output` (Input dataset)
>        - *"Does the dataset contain header:"*: `Yes`
>        - *"Choose how to select data by column:"*: `Select columns by column index number(s)`
>            - *"Select target column(s):"*: `c22`
>    - *"Whether to hold a portion of samples for test exclusively, nested CV?"*: `Nope`
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Remove beginning**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Remove beginning](Remove beginning1) %} with the following parameters:
>    - {% icon param-file %} *"from"*: `output` (Input dataset)
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Remove beginning**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Remove beginning](Remove beginning1) %} with the following parameters:
>    - {% icon param-file %} *"from"*: `output` (Input dataset)
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Ensemble methods**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Ensemble methods](toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_ensemble/sklearn_ensemble/1.0.11.0) %} with the following parameters:
>    - *"Select a Classification Task"*: `Load a model and predict`
>        - {% icon param-file %} *"Models"*: `outfile_object` (output of **Hyperparameter Search** {% icon tool %})
>        - {% icon param-file %} *"Data (tabular)"*: `output` (Input dataset)
>        - *"Does the dataset contain header:"*: `Yes`
>        - *"Select the type of prediction"*: `Predict class labels`
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Ensemble methods**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Ensemble methods](toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_ensemble/sklearn_ensemble/1.0.11.0) %} with the following parameters:
>    - *"Select a Classification Task"*: `Load a model and predict`
>        - {% icon param-file %} *"Models"*: `outfile_object` (output of **Hyperparameter Search** {% icon tool %})
>        - {% icon param-file %} *"Data (tabular)"*: `output` (Input dataset)
>        - *"Does the dataset contain header:"*: `Yes`
>        - *"Select the type of prediction"*: `Predict class labels`
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Remove beginning**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Remove beginning](Remove beginning1) %} with the following parameters:
>    - {% icon param-file %} *"from"*: `outfile_predict` (output of **Ensemble methods** {% icon tool %})
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Remove beginning**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Remove beginning](Remove beginning1) %} with the following parameters:
>    - {% icon param-file %} *"from"*: `outfile_predict` (output of **Ensemble methods** {% icon tool %})
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Plot confusion matrix, precision, recall and ROC and AUC curves**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Plot confusion matrix, precision, recall and ROC and AUC curves](toolshed.g2.bx.psu.edu/repos/bgruening/plotly_ml_performance_plots/plotly_ml_performance_plots/0.4) %} with the following parameters:
>    - {% icon param-file %} *"Select input data file :"*: `out_file1` (output of **Remove beginning** {% icon tool %})
>    - {% icon param-file %} *"Select predicted data file :"*: `out_file1` (output of **Remove beginning** {% icon tool %})
>    - {% icon param-file %} *"Select trained model :"*: `outfile_object` (output of **Hyperparameter Search** {% icon tool %})
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}

## Sub-step with **Plot confusion matrix, precision, recall and ROC and AUC curves**

> <hands-on-title> Task description </hands-on-title>
>
> 1. {% tool [Plot confusion matrix, precision, recall and ROC and AUC curves](toolshed.g2.bx.psu.edu/repos/bgruening/plotly_ml_performance_plots/plotly_ml_performance_plots/0.4) %} with the following parameters:
>    - {% icon param-file %} *"Select input data file :"*: `out_file1` (output of **Remove beginning** {% icon tool %})
>    - {% icon param-file %} *"Select predicted data file :"*: `out_file1` (output of **Remove beginning** {% icon tool %})
>    - {% icon param-file %} *"Select trained model :"*: `outfile_object` (output of **Hyperparameter Search** {% icon tool %})
>
>    ***TODO***: *Check parameter descriptions*
>
>    ***TODO***: *Consider adding a comment or tip box*
>
>    > <comment-title> short description </comment-title>
>    >
>    > A comment about the tool or something else. This box can also be in the main text
>    {: .comment}
>
{: .hands_on}

***TODO***: *Consider adding a question to test the learners understanding of the previous exercise*

> <question-title></question-title>
>
> 1. Question1?
> 2. Question2?
>
> > <solution-title></solution-title>
> >
> > 1. Answer for question1
> > 2. Answer for question2
> >
> {: .solution}
>
{: .question}


## Re-arrange

To create the template, each step of the workflow had its own subsection.

***TODO***: *Re-arrange the generated subsections into sections or other subsections.
Consider merging some hands-on boxes to have a meaningful flow of the analyses*

# Conclusion

Sum up the tutorial and the key takeaways here. We encourage adding an overview image of the
pipeline used.
