---
layout: tutorial_hands_on

title: "Foodborne Pathogen Detection from (direct Nanopore) sequencing data using Galaxy"
tags:
    - nanopore data analysis
    - host contamination filtering
    - pathogens detection
    - Strain identification
    - SNP Calling
    - SNP based pathogens identification
    - Gene based pathogens identification
    - Virulance factor
    - Phylogenetic tree
    - Heatmap
    - cyoa
level: Introductory
questions:
    - What are the steps to analize microbiome nanopore datasets?
    - How to indentify pathogens?
    - How to track the found pathogens through all your samples datasets?
objectives:
    - Check samples quality report generated by FastQC and NanoPlot for nanopore data
    - Pre-processing the data by quality improving and host contamination filtering
    - Taxonomy profiling indicating and visualizing up to spieces level in the samples
    - Gene based pathogenic identification via assembly, indentifing strains and indicating all genes in samples with a virclence factor 
    - SNP based pathogenic identification via SNP calling
    - Relating all samples' pathogenic genes for tracking pathogens via phylogenetic trees and heatmaps
time_estimation: "8h"
contributors:
    - bebatut
    - EngyNasr
---

# Introduction

Food contaminations with pathogens are a major burden on our society. In the year 2019, foodborne pathogens caused 137 diseases in Germany (BVL 2019). Globally, they affect an estimated 600 million people a year and impact socioeconomic development at different levels. These outbreaks are mainly due to Salmonella spp. followed by Campylobacter spp. and Noroviruses.

During the investigation of a foodborne outbreak, a microbiological analysis of the probable responsible food vehicle is performed in order to detect the responsible pathogens and track the contamination source. By default, to detect bacterial pathogens in food, the European Regulation (CE) follows ISO standards, but alternative methods with equivalent performance are possible. Usually, foodborne pathogens are detected and identified by stepwise cultures on selective media and/or targeting specific genes with real-time PCRs. To characterise the detected strains, the current gold standard is Pulsed-field Gel Electrophoresis (PFGE) or Multiple-Locus Variable Number Tandem Repeat Analysis (MLVA). These techniques have some disadvantages. Whole Genome Sequencing (WGS) has been proposed as an alternative: detection of all genes with just one sequencing run, phylogenetic analysis to link cases, information on antimicrobial resistance genes, virulence, serotype, resistance to sanitizers, root cause, and other critical factors in one assay, including historical reference to pathogen emergence. WGS is more than a surveillance tool and was recommended by the European Centre for Disease Prevention and Control (ECDC) and the European Food Safety Authority (EFSA) for surveillance and outbreak investigation. WGS still requires isolation of the targeted pathogen, which is a time-consuming, not always straightforward nor successful process. Sequencing methods without prior isolation could solve this issue.

The evolution of sequencing techniques in the last decades has made possible the development of shotgun metagenomic sequencing, i.e. the direct sequencing of all DNA present in a sample. This approach gives an overview of the genomic composition of all cells in the sample, including the food source itself, the microbial community and any possible pathogens and their complete genetic information, without the need for prior isolation. Several studies have demonstrated the potential of shotgun metagenomics to identify and characterise pathogens and their functional characteristics (e.g. virulence genes) in naturally contaminated or spiked food samples. 

The currently available studies used Illumina sequencing, generating short reads. Longer read lengths, generated by third generation sequencing platforms such as Pacific Biosciences (PacBio) and Oxford [Nanopore](https://nanoporetech.com/) Technologies (ONT), make it easier and more practical to identify strains with fewer reads. MinION (from Oxford Nanopore) is a portable, real-time device for ONT sequencing. Several proof-of-principle studies have shown the utility of ONT long read sequencing from metagenomic samples for pathogen identification. 

{% snippet faqs/galaxy/sequencing_nanopore.md %}

The industry partner of the datasets used in this tutorial, Biolytix, is a Swiss Small and Medium-sized Enterprise (SME)  founded in 1998, that specializes in molecular biology and microbiological analyses. They developed a procedure to extract, sequence using MinION (ONT) sequencing and analyse a food sample for foodborne pathogen detection and contamination source tracking. However, the bioinformatics pipelines are not following the best practices for open data science, not straightforward and can only be manipulated by the original author, making it not scalable. Therefore, the aim of the Galaxy workflows (step by step) presented in this tutorial is to modernise, FAIRify and validate the bioinformatic pipeline using modern paradigms of data science to make it accessible and scalable.

In this tutorial we will be presenting a Galaxy workflow it’s main goal is to agnostically detect and track pathogens in foods’ (chicken, cow, etc.) nanopore samples datasets and identifying contaminations, by identifying which samples are contaminated with a pathogen, what exactly is this pathogen and what is the degree of its severity (Virulence Factor). 
>
> <agenda-title></agenda-title>
>
> In this tutorial, we will deal with:
>
> 1. TOC
> {:toc}
>
{: .agenda}

# Dataset

In this tutorial, the datasets are all generated by Biolytix. They are all chicken spiked with Salmonella's different stains. The two barcodes we are using are; Barcode 10 Spike 2, which is chicken spiked with Salmonella enterica subsp. Enterica this dataset was generated on the 14th of July 2022, and Barcode 11 Spike 2b, which is chicken spiked with Salmonella enterica subsp. Houtenae generated on 20th of July 2022.

![Biolytix workflow for sequencing ONT datasets](../../images/Biolytix_Workflow_Sequencing.png "The Biolytix workflow for spiking food e.g. chicken, meat, etc. with known pathogens e.g. Salmonella then preform Nanopore sequencing datasets with built-in base caller")

# Create your histories and Get Data

> <hands-on-title>Data upload</hands-on-title>
>
> 1. Create two new histories for this tutorial one for every sampling time; Barcode 10 and Barcode 11.
> 2. Import the files from Galaxy shared data libraries to each history respectivly:
>
>    - Click on __Shared Data__ menu (top panel) then __Data libraries__
>    - Navigate to folder __Biolytix__ then __Spiked__ then __Salmonella__ then __Spike2__ then __Spike 2 Barcode 10 - 15 collapsed__
>    - Select the following file
>     ```
>     Barcode 10
>     ```
>    - Click on the __Export to History__ button near the top and select __as Datasets__ from the dropdown menu
>    - In the pop-up window, select the first history you created to import the file to
>    - Click on Import
> 3. Repeat step 2 again for the second history, but this time:
>    - Navigate to folder __Biolytix__ then __Spiked__ then __Salmonella__ then __Spike2b__	then __Spike2b Barcode 10-15 and unclassified Collapsed__
>    - Select the following file
>     ```
>     Barcode 11
>     ```
>
>    {% snippet faqs/galaxy/datasets_import_via_link.md %}
>    {% snippet faqs/galaxy/datasets_import_from_data_library.md %}
>
>
{: .hands_on}

# Choose your own tutorial
{% include _includes/cyoa-choices.html option1="ShortVersion" option2="LongVersion" default="ShortVersion" %}

<div class="ShortVersion" markdown="1">

As you chose to follow the short version of the tutorial we will be running the complete sub-workflows each for complete task starting from the pre-processing of the sequenced datasets till the pathogen tracking among all our chosen samples. In order to check the step by step tools used for every sub-workflow please follow the tutorial LongVersion.

# Pre-Processing

Before starting any analysis, it is always a good idea to assess the quality of your input data and improve it where possible by trimming and filtering reads.

In this section we will run a workflow that performs the following tasks:
1. Assess read quality before and after trimming using **FastQC** {% icon tool %}, **Nanoplot** {% icon tool %} and  **MultiQC** {% icon tool %}
2. Filter reads by length and quality, quality improving using **Porechop** {% icon tool %} and **Fastp** {% icon tool %}
3. Remove all possible host contamination sequences e.g. Chicken, Cow, etc **Kraken2** {% icon tool %} with Kalamri database, **Filter Tabular** {% icon tool %} and **Filter Sequence By ID** {% icon tool %}

We will run all these steps using a single sub-workflow, then discuss each step and the results in more detail. Please do the same steps for both histories; Barcode 10 and Barcode 11.

> <hands-on-title>Pretreatments</hands-on-title>
>
> 1. **Import the workflow** into Galaxy
>    - Copy the URL (e.g. via right-click) of [this workflow]({{ site.baseurl }}{{ page.dir }}workflows/nanopore_preprocessing.ga) or download it to your computer.
>    - Import the workflow into Galaxy
>
>    {% snippet faqs/galaxy/workflows_import.md %}
>
> 2. Run **Workflow 1:  Nanopore Datasets - Pre-Processing** {% icon workflow %} using the following parameters:
>    - *"Send results to a new history"*: `No`
>    - {% icon param-file %} *"1: Nanopore reads of a sample"*: `Barcode 10`
>    - {% icon param-file %} *"2: Host to Remove Specifier"*: `^.*Gallus|Homo|Bos.*$`
>    - {% icon param-file %} *"5: Porechop Output format for the reads"*: `fastq.qz`
>
>    {% snippet faqs/galaxy/workflows_run.md %}
>
{: .hands_on}

The workflow will take a little while to complete. Once tools have completed, the results will be available in your history for viewing. Note that only the most important outputs will he visible; intermediate files are hidden by default.

While you wait for the workflow to complete, please run the same workflow for the second history with Barcode 11 and continue reading in the next section(s) we will go into a bit more detail about what happens in each step of this workflow and examine the results.

## Quality Control

During sequencing, errors are introduced, such as incorrect nucleotides being called. These are due to the technical limitations of each sequencing platform. Sequencing errors might bias the analysis and can lead to a misinterpretation of the data.

Sequence quality control is therefore an essential first step in your analysis.
In this tutorial we use similar tools as described in the tutorial ["Quality control"]({% link topics/sequence-analysis/tutorials/quality-control/tutorial.md %}):
- [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) generates a web report that will aid you in assessing the quality of your data
- [NanoPlot](https://github.com/wdecoster/NanoPlot) plotting tool for long read sequencing data and alignments
- [MultiQC](https://multiqc.info/) combines multiple FastQC reports into a single overview report, in this tutorial to check the quality of the sequencing before and after trimming and quality improvement
- [Porechop](https://github.com/rrwick/Porechop) and [Fastp](https://academic.oup.com/bioinformatics/article/34/17/i884/5093234) for trimming and filtering

For more information about how to interpret the plots generated by FastQC and MultiQC, please see our dedicated Quality Control Tutorial.

> <question-title></question-title>
>
> Inspect the webpage output from MultiQC for barcode 10 sample history
>
> 1. How many sequences does file has before and after trimming?
> 2. How is the quality score over the reads before and after trimming? And the mean score?
> 3. What is the importance of FastQC?
>
> > <solution-title></solution-title>
> >
> > 1. Before trimming the file has 114986 sequences and After trimming the file has 91434 sequences
> > 2. The "Per base sequence quality" is globally medium: the quality score stays between 20 and 25 over the reads after trimming, however, bad quality of reads is seen below 20 before trimming sepcially at the beginning and the end of the read.
> >
> >    ![Sequence Quality](../../images/fastqc_per_base_sequence_quality_plot_barcode10.png)
> >
> > 3. After checking what is wrong, e.g. before trimming, we should think about the errors reported by FastQC: they may come from the type of sequencing or what we sequenced (check the ["Quality control" training]({% link topics/sequence-analysis/tutorials/quality-control/tutorial.md %}): [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) for more details). However, despite these challenges, we can already see sequences getting slightly better after the trimming, so we can proceed with our analyses.
> {: .solution}
{: .question}

## Hosts Filtering
Generally, we are not intersted in the food (host) sequences that may or may not include the pathogen, rather we are intersted only in the pathogen itself. Thats why it's an important step to get rid of all hosts' sequences so we are only remained with sequences that might include a pathogen to start our analyses on. To use these workflows in real life you just run them on samples collected from, for example, a food factory at different time points and locations in the production process in order to spot when and where the pathogen entered the food and affect it. The workflow will filter out all possible hosts, e.g. meat, milk, etc then remove all found hosts out, and keep the remaining sequences to test and track pathogens for. In this tutorial, we know in prior that the samples we have are chicken spiked with salmonella so we already know what will we get. 

In this tutorial we use the following tools and database to remove all hosts' sequences:
- [Kraken2](https://ccb.jhu.edu/software/kraken2/) a taxonomic classification system, uses build in and external libraries to classify the sequences into known taxon up to spieces level
- [Kalamari](https://github.com/lskatz/Kalamari) A database of completed assemblies for metagenomics-related tasks
- [Filter Tabular](https://toolshed.g2.bx.psu.edu/repository?repository_id=48120541c8d5534d&changeset_revision=34d29339abab) Provides tools for manipulation of tablular files, used to filter all hosts out
- [Filter sequences by ID](http://toolshed.g2.bx.psu.edu/view/peterjc/seq_filter_by_id) By default it divides a FASTA, FASTQ or Standard Flowgram Format (SFF) file in two, those sequences with or without an ID present in the tabular file column(s) specified. You can opt to have a single output file of just the matching records, or just the non-matching ones.

> <question-title></question-title>
>
> Inspect the webpage output from MultiQC for barcode 10 sample history
>
> 1. What is the speices of the host?
> 2. How many sequences of this host is found?
>
> > <solution-title></solution-title>
> >
> > 1. Gallus gallus (taxid 9031), which is Chicken
> > 2. 836
> >
> {: .solution}
{: .question}

# Taxonomy Profiling
In this sub-workflow we will learn about the different taxonomy levels in our samples starting from the kingdom level up to the spieces level and visualize that. It's important in our testcase to check what might be the spieces of a possible pathogen to be found, it gets us closer to the investigation as well as discovering possible multiple food infections if any exsisted.

{% snippet topics/metagenomics/faqs/taxon.md %}

If you have not yet noticed, in the previous sub-workflow we ran **Kraken2** along with **Kalamari** database, which is also a kind of taxonomy profiling but the database used is designed to include all possible hosts' sequences that we need to filter them out. In this sub-workflow, we will run **Kraken2** again but this time with one of its built-in databases **Standard PlusPF**, which can give us more insight of possible spieces that can be pathogenic candidates than **Kalamari**, you can test this yourself by comparing reports of both **Kraken2** runs.

In this section we will run a sub-workflow that performs the following tasks:
1. Taxonomy profiling using **Kraken2** {% icon tool %} with **Standard PlusPF** database
2. Generate a kraken-biom report needed for the interactive visualization using **Kraken-biom** {% icon tool %}
3. Taxonomy visualization with one of the interactive tools in Galaxy, **Phinch Visualisation** {% icon tool %}, prefereably to use on Chrome

> <details-title>Kraken2 and the k-mer approach for taxonomy classification</details-title>
>
> In the $$k$$-mer approach for taxonomy classification, we use a database containing DNA sequences of genomes whose taxonomy we already know. On a computer, the genome sequences are broken into short pieces of length $$k$$ (called $$k$$-mers), usually 30bp.
>
> **Kraken** examines the $$k$$-mers within the query sequence, searches for them in the database, looks for where these are placed within the taxonomy tree inside the database, makes the classification with the most probable position, then maps $$k$$-mers to the lowest common ancestor (LCA) of all genomes known to contain the given $$k$$-mer.
>
> ![Kraken2](../../images/metagenomics-nanopore/kmers-kraken.jpg "Kraken sequence classification algorithm. To classify a sequence, each k-mer in the sequence is mapped to the lowest common ancestor (LCA, i.e. the lowest node) of the genomes that contain that k-mer in the database. The taxa associated with the sequence's k-mers, as well as the taxa's ancestors, form a pruned subtree of the general taxonomy tree, which is used for classification. In the classification tree, each node has a weight equal to the number of k-mers in the sequence associated with the node's taxon. Each root-to-leaf (RTL) path in the classification tree is scored by adding all weights in the path, and the maximal RTL path in the classification tree is the classification path (nodes highlighted in yellow). The leaf of this classification path (the orange, leftmost leaf in the classification tree) is the classification used for the query sequence. Source: {% cite Wood2014 %}")
>
{: .details}

We will run all these steps using a single sub-workflow, then discuss each step and the results in more detail. Please do the same steps for both histories; Barcode 10 and Barcode 11.

> <hands-on-title>Taxonomy Profiling</hands-on-title>
>
> 1. **Import the workflow** into Galaxy
>    - Copy the URL (e.g. via right-click) of [this workflow]({{ site.baseurl }}{{ page.dir }}workflows/nanopore_taxonomy_profiling_and_visualization.ga) or download it to your computer.
>    - Import the workflow into Galaxy
>
>    {% snippet faqs/galaxy/workflows_import.md %}
>
> 2. Run **Workflow 2: Nanopore Datasets - Taxonomy Profiling and Visualization** {% icon workflow %} using the following parameters:
>    - *"Send results to a new history"*: `No`
>    - {% icon param-file %} *"Nanopore preprocessed reads"*: `Nanopore processed sequenced reads` the output from **Filter Sequence By ID** {% icon tool %} from the **Pre-Processing** sub-workflow
>    - {% icon param-file %} *"Optional for visualization: Sample Metadata"*: `leave empty`
>
>    {% snippet faqs/galaxy/workflows_run.md %}
>
{: .hands_on}

During the workflow is running you can move on to the next section **Gene based pathogentic indentification** and run the sub-workflow there as well.

> <question-title></question-title>
>
> Inspect the **Kraken2** report for barcode 10 sample history
>
> 1. What is the most found spieces?
> 2. What is the second most found spieces?
> 3. How many sequences are classified and How many are unclassified? 
> 4. What are the difference between **Kraken2**{% icon tool %} report with **Kalamari** and **Kraken2** report with **Standard PlusPF** with regards to the previous 3 questions
>
> > <solution-title></solution-title>
> >
> > 1. Escherichia coli with 10,243 sequences
> > 2. Salmonella enterica with 7,458 sequences
> > 3. 40,143 sequences are classified and 50,455 are unclassified
> > 4. a. with **Kalamari** the most found spieces is Escherichia coli with 12,577 sequences 
> > >  b. with **Kalamari** the second most found spieces is Salmonella enterica with 10,632 sequences
> > > >  c. with **Kalamari** the number of classified sequences are 32,020 sequences and the unclassified sequences are 59,414 
> > > > > In conclusion, both databases are able to show the same results of the most common spieces. However, the number of the classified sequences with **Standard PlusPF** is higher than **Kalamari** and it would be even higher since all chicken sequences were removed before testing the **Standard PlusPF**
> {: .solution}
{: .question}

## Visualization
In order to view the taxonomy profiling produced by **Kraken2** there are alot of tools to be used afterwards such as **Krona pie chart** {% icon tool %}, however the spieces classified are a lot to be shown by this tool. For that reason, we have chosen the [Phinch visualization](https://www.phinch.org/){% icon tool %} interactive tool as it contamins multiple visulaization plots, it's interactive you can choose between different parameters, you can visualize each taxonomic level on its own, you can have your metadate of the samples represented along with the taxonomic visulaization, download all plots for publications and a lot of other benfits.

**Phinch visualization** {% icon tool %} needs a Biom file format as an input for that we needed the [Kraken-Biom](https://github.com/smdabdoub/kraken-biom) tool {% icon tool %} to convert the **Kraken2** tabular output into a Biom file. 

Now lets try the **Phinch visulization** {% icon tool %} running for barcode 11 sample history

> <hands-on-title>Explore data interactively</hands-on-title>
>
> 1. Open interactive tool
>
>    {% snippet faqs/galaxy/interactive_tools_open.md tool="Phinch visulization" %}
>
> 2. Click on **Proceed to Gallery** button on the top right of the opened webpage to see all the plots
>
{: .hands_on}

> <question-title></question-title>
>
> 1. What is the most found spieces?
> 2. What is the second most found spieces?
> 3. What's your favorite visualization plot?
>
> > <solution-title></solution-title>
> >
> > 1. Salmonella enterica with 17,309 sequences
> > 2. Pseudomonas lundensis with 13,227 sequences
> > 3. All of them are good visualizaton to the data but for us to answer these questions, we used **Taxonomy Bar chart**
> >
> >    ![Taxonomy Bar Chart](../../images/phinch_taxonomy_bar_chart.png)
> >
> {: .solution}
{: .question}
 
# Gene based pathogenic identification
In this sub-workflow we will analyse the sequences in our samples and identify genes that have a [Virulence Factor (VF)](https://www.sciencedirect.com/topics/immunology-and-microbiology/virulence-factor), which will then define a pathogen and its severity level. We will also identify [Antimicrobial Resistance genes (AMR)](https://www.sciencedirect.com/topics/engineering/antibiotic-resistance-genes), which their presence will destroy the antibiotic that will lead to not altering the target site and spread throughput the pathogenic bacteria decreasing the overall fitness of the host. Using [Multilocus Sequence Typing (MLST)](https://pubmlst.org/) database we will also determain the strain of the bacteria we are testing for pathogenitiy. Never the less, we will be creating our Fasta and Tabular files that we will use to track and visualize our pathogenic identification thoughout all samples, which is done in the **Pathogen Tracking among all samples** sub-workflow coming later in this tutorial.

In this section we will run a sub-workflow that performs the following tasks:
1. Genome assembly or creating contigs from our sequences using **metaFlye** {% icon tool %} then assembly polishing using **medaka consensus pipeline** {% icon tool %} and visualizing the assembly graph using **Bandage Image** {% icon tool %}
2. Generate an **MLST** report with **MLST** {% icon tool %} that scans genomes against PubMLST schemes
3. Generate reports with **AMR** genes and genes with **VF** using **ABRicate** {% icon tool %}
4. Manipulate tabular reports to prepare them for **Pathogen Tracking among all samples** sub-workflow using tools such as **Cut**{% icon tool %}, **Replace**{% icon tool %}, **Add line to file**{% icon tool %}, **Compose text parameter value**{% icon tool %}, **Tabular-to-FASTA**{% icon tool %} and **Concatenate datasets**{% icon tool %}

We will run all these steps using a single sub-workflow, then discuss each step and the results in more detail. Please do the same steps for both histories; Barcode 10 and Barcode 11.

But before we run the sub-workflow we need to upload one more file needed to create a report for this sub-workflow **MLST** analysis.

> <hands-on-title>Data upload</hands-on-title>
>
> 1. Import the files from Galaxy shared data libraries to both histories:
>
>    - Click on __Shared Data__ menu (top panel) then __Data libraries__
>    - Navigate to folder __Biolytix__
>    - Select the following file
>     ```
>     MLST Report with Header
>     ```
>    - Click on the __Export to History__ button near the top and select __as Datasets__ from the dropdown menu
>    - In the pop-up window, select the first history you created to import the file to
>    - Click on Import
> 2. Repeat the first step again for the second history
>
>    {% snippet faqs/galaxy/datasets_import_via_link.md %}
>    {% snippet faqs/galaxy/datasets_import_from_data_library.md %}
>
>
{: .hands_on}

> <hands-on-title>Taxonomy Profiling</hands-on-title>
>
> 1. **Import the workflow** into Galaxy
>    - Copy the URL (e.g. via right-click) of [this workflow]({{ site.baseurl }}{{ page.dir }}workflows/nanopore_gene_based_pathogenic_identification.ga) or download it to your computer.
>    - Import the workflow into Galaxy
>
>    {% snippet faqs/galaxy/workflows_import.md %}
>
> 2. Run **Workflow 2: Nanopore Datasets - Gene based Pathogenic Identification** {% icon workflow %} using the following parameters:
>    - *"Send results to a new history"*: `No`
>    - {% icon param-file %} *"Nanopore Preprocessed reads"*: `Nanopore processed sequenced reads` the output from **Filter Sequence By ID** {% icon tool %} from the **Pre-Processing** sub-workflow
>    - {% icon param-file %} *"Sample ID"*: `Spike2Barcode10` or `Spike2bBarcode11` respectively to the history
>    - {% icon param-file %} *"MLST Report Header"*: `MLST Report with Header` file you have just uploaded to your history 
>
>    {% snippet faqs/galaxy/workflows_run.md %}
>
{: .hands_on}

## Assembly
After improving the quality of the sequences in our samples and removing all the hosts' sequences, the next step is to analysis them and search for pathogens. To do so, we have to first assemble our reads and create our contigs file, which will then be used to search databases with.

Recent advances in the challenging area of metagenomic bacterial genome assembly in the form of the specialized long-read metagenomic assembly program [metaflye](https://www.nature.com/articles/s41592-020-00971-x) and sequence polishing tools such as [medaka](https://github.com/nanoporetech/medaka) have made the inclusion of these analyses relatively simple. Metaflye and medaka facilitate the rapid assembly and correction of the long, error-prone nanopore reads obtained from the metagenomic sequencing in multiple earlier work.

For visualizing the assembly graph output from **Flye**{% icon tool %} we have chosen [Bandage Image](https://rrwick.github.io/Bandage/){% icon tool %}.

> <question-title></question-title>
>
> Inspect **Flye**{% icon tool %} and **Medaka consensus pipeline**{% icon tool %} output results from barcode 10 sample history
>
> 1. How many different contigs you got after **Flye**{% icon tool %} and how many are left after **Medaka consensus pipeline**{% icon tool %}, and what does that mean?
> 2. What is your result of the **Bandage Image**{% icon tool %}?
>
> > <solution-title></solution-title>
> >
> > 1. After **Flye**{% icon tool %} we have got 115 contigs and after **Medaka consensus pipeline**{% icon tool %} all 115 contigs were kept, the quality of the **Flye**{% icon tool %} run was high that the polishing didnot remove any of the contigs.
> > > 2.
> >
> >    ![Bandage Image Barcode 10 Assembly Graph](../../images/bandage_image_flye_graph.png)
> >
> {: .solution}
{: .question}

## MLST Database
**MLST** {% icon tool %} is used to scan the [MLST](https://pubmlst.org/) database against PubMLST typing schemes. It's one of the analysis that you can perform on your dataset to deterimine the allele IDs you can also detect novel allels. For the further analysis of this tutorial, this step is not important to identify pathogens and track them, however we wanted to show some of the analysis that one can use Galaxy in and understand more about the dataset as well as identifying the strain that might be a pathogen or not. 

The output file of the **MLST** {% icon tool %} is a tab-seperated output file which contains: - the filename - the closest PubMLST scheme name - the ST (sequence type) - the allele IDs. 

> <question-title></question-title>
>
> Inspect **MLST** {% icon tool %} results from barcode 11 sample history
>
> 1. What is the the closest PubMLST typing scheme name detected by the tool?
>
> > <solution-title></solution-title>
> >
> > 1. senterica_achtman_2 ({% cite sentericaachtman2 %})
> >
> {: .solution}
{: .question}

## Antimicrobial Resistance Genes
Now, we want to search our samples' contigs for **AMR** genes for that we run **ABRicate** {% icon tool %} and chose the **NCBI Bacterial Antimicrobial Resistance Gene Database** from the advanced options of the tool.

The tool will identify if there is an AMR found or not, in which contig, in which location on the contig, what is the name of the exact product, what does it resist against and alot of other information regarding the found **AMR**

> <question-title></question-title>
>
> Inspect **AMR Identified by NCBI** output file from barcode 10 and barcode 11 samples' histories
>
> 1. How many **AMR** genes found in barcode10 sample, what are they, give more details about them?
> 2. How many **AMR** genes found in barcode10 sample, what are they, give more details about them?
>
> > <solution-title></solution-title>
> >
> > 1. Only one **AMR** gene is found and it is tet(C), which resists [TETRACYCLINE](https://medlineplus.gov/druginfo/meds/a682098.html). It's found in contig 109 from the position 1634 till 2809, with 100% coverage, so 100% of gene is covered in this contig.
> > 2. No **AMR** genes are found by the database in barcode11. 
> >
> {: .solution}
{: .question}

## Virulence Factor Database
In this step we return back to the main goal of the tutorial where we want to identify the pathogens. 


# SNP based pathogenic identification
this output can be used to have the full genome 

# Pathogen Tracking among all samples
# Create your histories and Get Data

> <hands-on-title>Copy datasets from our two histories to a new history</hands-on-title>
>
> 1. Create a new history for for this part of the tutorial where we will create collections of the results of the samples' histories needed to track and visualize our found pathogens.
>
>    {% snippet faqs/galaxy/histories_create_new.md %}
>    {% snippet faqs/galaxy/histories_copy_dataset.md %}
>
>
{: .hands_on}
</div>


<div class="LongVersion" markdown="1">

As you chose to use the long version 
Detail boxes 
More explaination in different choices

</div>

# Conclusion

Sum up the tutorial and the key takeaways here. We encourage adding an overview image of the
pipeline used.

